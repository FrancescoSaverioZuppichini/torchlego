{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.models import resnet34\n",
    "from torchlego.models.resnet import ResNetBasicBlock\n",
    "from torchlego.utils import ModuleTransfer, Tracker\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34_my = nn.Sequential(\n",
    "    nn.Conv2d(3,\n",
    "                      64,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "    ResNetBasicBlock(64, 64),\n",
    "    ResNetBasicBlock(64, 64),\n",
    "    ResNetBasicBlock(64, 64),\n",
    "    ResNetBasicBlock(64, 128),\n",
    "    ResNetBasicBlock(128, 128),\n",
    "    ResNetBasicBlock(128, 128),\n",
    "    ResNetBasicBlock(128, 128),\n",
    "    ResNetBasicBlock(128, 256),\n",
    "    ResNetBasicBlock(256, 256),\n",
    "    ResNetBasicBlock(256, 256),\n",
    "    ResNetBasicBlock(256, 256),\n",
    "    ResNetBasicBlock(256, 256),\n",
    "    ResNetBasicBlock(256, 256),\n",
    "    ResNetBasicBlock(256, 512),\n",
    "    ResNetBasicBlock(512, 512),\n",
    "    ResNetBasicBlock(512, 512),\n",
    "    nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, 1000)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_model = resnet34(True).eval().cpu()\n",
    "dest_model = resnet34_my.eval()\n",
    "\n",
    "x = torch.zeros((1, 3, 224, 244))\n",
    "\n",
    "src_tr = Tracker(src_model)\n",
    "dest_tr = Tracker(dest_model)\n",
    "\n",
    "src_operations = src_tr(x).parametrized\n",
    "dest_operations = dest_tr(x).parametrized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for src_op, dest_op in zip(src_operations, dest_operations):\n",
    "# #   \n",
    "#     print('-------')\n",
    "#     print(src_op, '|', dest_op)\n",
    "#     if 'weight' in dest_op.state_dict().keys():\n",
    "#         assert dest_op.state_dict()['weight'].sum() != src_op.state_dict()['weight'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) | Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Linear(in_features=512, out_features=1000, bias=True) | Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for src_op, dest_op in zip(src_operations, dest_operations):\n",
    "#     print(f'Transfered from={src_op} to={dest_op}')\n",
    "    print('-------')\n",
    "    print(src_op, '|', dest_op)\n",
    "    dest_op.load_state_dict(src_op.state_dict())\n",
    "    if 'weight' in dest_op.state_dict().keys():\n",
    "        assert dest_op.state_dict()['weight'].sum() == src_op.state_dict()['weight'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) | Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "tensor(-1.3706) Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "tensor(-1.3706) Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.8200) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.8200) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-82.0177) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-82.0177) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(17.9955) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(17.9955) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-4.9183) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-4.9183) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.0260) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.0260) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-76.2302) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-76.2302) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.5636) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.5636) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-18.9897) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-18.9897) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.7638) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.7638) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-42.2386) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-42.2386) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.9622) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(16.9622) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-22.2830) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-22.2830) Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(15.9482) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(15.9482) BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-56.0927) Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-56.0927) Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(34.1530) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(34.1530) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-117.7095) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-117.7095) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(32.6522) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(32.6522) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(-3.3827) Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(-3.3827) Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(27.8456) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(27.8456) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-106.8647) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-106.8647) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(30.3040) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(30.3040) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-220.4118) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-220.4118) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(23.5767) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(23.5767) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-110.0694) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-110.0694) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(32.5767) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(32.5767) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-140.3098) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-140.3098) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(22.2888) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(22.2888) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-224.0900) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-224.0900) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(31.3989) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(31.3989) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-120.7980) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-120.7980) Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(22.6127) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(22.6127) BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-252.5307) Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-252.5307) Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(69.9382) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(69.9382) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-217.8013) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-217.8013) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(73.5475) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(73.5475) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(-26.8424) Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(-26.8424) Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(33.9990) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(33.9990) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-545.9394) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-545.9394) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(59.6046) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(59.6046) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-504.3118) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-504.3118) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(40.7006) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(40.7006) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-695.5151) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-695.5151) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(55.9823) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(55.9823) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-451.8211) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-451.8211) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(40.8640) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(40.8640) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-678.9666) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-678.9666) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(53.3172) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(53.3172) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-540.3823) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-540.3823) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(42.2159) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(42.2159) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-728.5297) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-728.5297) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(53.8725) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(53.8725) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-586.1949) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-586.1949) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(43.5570) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(43.5570) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-597.2974) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-597.2974) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(57.2764) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(57.2764) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-756.7316) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-756.7316) Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(47.1892) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(47.1892) BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) | Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-661.0831) Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "tensor(-661.0831) Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(130.2861) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(130.2861) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-911.3850) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-911.3850) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(378.9204) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(378.9204) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) | Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(22.7704) Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "tensor(22.7704) Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(223.6319) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(223.6319) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-3394.7524) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-3394.7524) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(119.5414) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(119.5414) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-644.6702) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-644.6702) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(312.9650) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(312.9650) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-3628.4873) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(-3628.4873) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(124.8074) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(124.8074) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) | Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(188.3578) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "tensor(188.3578) Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "-------\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) | BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(708.5010) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor(708.5010) BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-------\n",
      "Linear(in_features=512, out_features=1000, bias=True) | Linear(in_features=512, out_features=1000, bias=True)\n",
      "tensor(0.0237) Linear(in_features=512, out_features=1000, bias=True)\n",
      "tensor(0.0237) Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for src_op, dest_op in zip(src_operations, dest_operations):\n",
    "    print('-------')\n",
    "    print(src_op, '|', dest_op)\n",
    "    if 'weight' in src_op.state_dict().keys():\n",
    "            print(dest_op.state_dict()['weight'].sum(), dest_op)\n",
    "            print(src_op.state_dict()['weight'].sum(), src_op)\n",
    "            assert dest_op.state_dict()['weight'].sum() == src_op.state_dict()['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7581e-01, -2.4327e-01, -2.2948e+00, -1.9053e+00, -2.4730e+00,\n",
       "         -2.1047e-01, -3.5750e+00, -1.7740e+00, -1.9271e+00, -9.9620e-01,\n",
       "          1.6648e+00, -4.0727e-01, -1.0489e+00, -1.4315e+00, -1.5815e+00,\n",
       "         -7.8157e-01, -7.4532e-01, -1.7407e+00, -2.1929e+00, -1.5676e+00,\n",
       "         -1.9657e+00,  6.2797e-01, -9.6306e-01, -6.2646e-01, -1.6638e+00,\n",
       "         -2.4488e+00, -1.5220e+00, -1.8061e+00, -2.9531e-01, -9.5689e-01,\n",
       "         -4.1994e+00, -1.6529e+00, -2.1386e+00, -1.8823e+00, -1.0101e+00,\n",
       "         -3.7073e+00, -1.9570e+00, -3.5193e+00,  5.8777e-01, -1.9691e+00,\n",
       "         -7.9854e-01, -1.2132e+00, -3.8929e-01,  1.2133e+00, -9.5485e-01,\n",
       "         -4.0284e-01, -1.1763e+00, -8.9208e-01, -1.9620e+00, -3.0837e+00,\n",
       "         -2.4837e+00,  8.9620e-01, -7.8899e-01, -1.2444e+00, -1.4835e+00,\n",
       "         -2.8464e+00, -2.3781e+00, -3.0220e+00, -3.1995e+00,  1.3249e+00,\n",
       "         -7.2586e-01, -2.5133e+00,  1.6638e-01,  3.1705e-01, -7.1929e-02,\n",
       "         -5.3640e-01,  1.0295e-01, -2.5600e+00,  7.7942e-01, -7.7585e-01,\n",
       "         -1.1670e+00, -1.2409e+00, -1.2985e+00,  2.7721e+00, -2.1506e+00,\n",
       "         -3.0375e-01, -2.1032e+00, -1.9884e+00,  1.6839e+00, -2.7577e-01,\n",
       "          1.3132e+00, -1.0702e+00, -1.3695e+00, -2.1457e-01, -2.2169e+00,\n",
       "         -1.3522e+00, -5.6097e-01, -8.7562e-02, -1.4033e+00, -6.5542e-01,\n",
       "         -2.0794e+00, -8.7467e-01, -5.9160e-01, -2.1492e+00, -2.3209e+00,\n",
       "          1.6891e-01, -2.0613e+00, -3.3705e+00,  1.1662e+00, -8.3245e-01,\n",
       "         -1.3602e+00,  8.7632e-01, -1.6762e+00,  1.3720e+00, -1.4083e+00,\n",
       "         -1.6881e+00, -2.1070e+00, -1.2710e+00, -2.8458e+00, -1.5477e+00,\n",
       "         -2.6597e+00,  3.5804e+00, -1.0119e+00, -1.5849e+00, -1.9400e+00,\n",
       "         -3.7408e+00, -1.7316e+00,  1.5046e+00, -2.0152e+00, -2.9823e+00,\n",
       "         -2.3851e+00, -2.0872e+00, -1.4744e+00, -3.1577e+00, -2.9992e+00,\n",
       "         -1.6322e+00,  9.4645e-01, -9.8129e-01,  1.3321e+00, -1.6527e+00,\n",
       "         -2.2768e+00, -2.1306e+00, -1.8192e+00, -1.7746e+00, -1.8930e+00,\n",
       "         -1.1564e-01, -2.9867e+00, -2.0714e+00, -1.1884e+00, -2.7790e+00,\n",
       "         -2.6863e+00, -7.8634e-01, -1.0347e+00, -1.2368e+00, -1.9683e+00,\n",
       "         -5.5666e-02, -2.5832e-01,  3.6031e-01, -1.3363e+00,  6.0761e-01,\n",
       "         -4.8343e-01,  1.4115e-01,  1.6733e+00, -9.9791e-02, -6.8208e-02,\n",
       "         -5.3669e-01, -4.0609e-02, -7.7106e-01,  1.3612e+00,  1.7870e-01,\n",
       "         -1.3043e-02, -1.0130e+00, -1.4132e+00,  5.1022e-02,  4.5194e-01,\n",
       "          9.6733e-01,  1.2565e+00,  1.0161e+00,  1.5242e+00, -8.5839e-01,\n",
       "         -9.4580e-01, -3.3924e-01, -5.6126e-01, -5.7542e-01,  2.4383e-02,\n",
       "         -1.0248e-01, -1.0171e+00, -8.1178e-01, -4.1765e-01, -1.1828e+00,\n",
       "         -1.0323e+00,  7.8326e-01, -1.2737e+00,  6.9864e-01, -5.2549e-01,\n",
       "          6.7328e-01, -5.9514e-01,  3.1796e-01,  2.7238e-01,  1.9678e-01,\n",
       "          1.6584e+00, -1.0116e+00, -1.1024e+00, -9.9737e-01,  7.8572e-01,\n",
       "         -3.0175e-02, -1.5036e+00, -1.5265e+00, -9.5965e-01, -7.3548e-01,\n",
       "         -4.4472e-02, -1.8099e+00, -2.3086e-01, -2.8251e-01, -7.9630e-01,\n",
       "         -1.6597e+00,  5.1289e-01,  1.5436e-01, -2.5325e-01, -5.5411e-01,\n",
       "          6.4743e-01, -1.6378e+00, -9.5787e-01, -1.5387e+00, -1.1605e+00,\n",
       "         -2.3075e-01, -1.0414e-01, -1.0750e+00, -1.2473e+00, -1.5180e+00,\n",
       "          5.6684e-01,  8.7548e-01, -3.9811e-01, -4.8407e-01, -4.3806e-01,\n",
       "         -7.7540e-01, -9.4063e-01, -2.7500e-01,  9.6019e-01, -2.9739e-01,\n",
       "         -1.3886e+00, -1.6496e+00, -5.6478e-01, -9.4133e-01, -1.2558e+00,\n",
       "         -4.1203e-01,  5.7338e-01, -6.9118e-01, -1.1736e+00, -1.7971e+00,\n",
       "         -1.3849e+00,  6.9894e-01, -1.6228e+00, -3.5311e-01, -1.1085e+00,\n",
       "         -4.0942e-01, -8.0359e-02, -8.6635e-01,  4.4706e-01, -7.8113e-02,\n",
       "          3.5134e-02, -8.4342e-01,  1.0982e+00, -4.1953e-01, -4.9197e-01,\n",
       "         -1.5255e+00, -5.5978e-01, -7.4430e-01,  4.8341e-01, -7.4327e-01,\n",
       "         -8.4659e-01,  1.2850e-02,  1.1232e+00, -7.5626e-01, -1.0639e+00,\n",
       "         -1.6374e-01,  1.1506e-01, -6.5056e-01,  9.6925e-01, -3.6962e-01,\n",
       "         -1.1552e-01, -8.0188e-01, -1.2658e-01,  3.8200e-01,  2.0108e-01,\n",
       "         -4.5344e-01,  2.2526e-01,  1.3947e-01,  4.3588e-01,  5.3917e-01,\n",
       "          2.8710e-02,  7.2650e-01,  3.7917e-01,  2.5332e+00,  9.0858e-01,\n",
       "          1.8092e+00, -8.8829e-01, -5.7052e-01,  1.7513e-01, -1.4640e+00,\n",
       "         -1.3814e+00,  1.9585e-01,  2.7141e-01,  3.7419e-01,  7.6839e-02,\n",
       "         -1.0274e+00,  2.7901e-01, -2.3123e-01, -4.6017e-01, -5.4064e-02,\n",
       "         -1.5334e+00, -9.2549e-01, -2.0649e-01, -6.1379e-01, -2.1027e+00,\n",
       "         -3.1208e+00, -1.0726e+00, -8.4162e-01, -1.7463e+00, -3.0136e+00,\n",
       "          1.4538e+00, -1.9595e+00, -1.4885e+00, -1.8362e+00, -3.6970e-01,\n",
       "         -1.2272e+00, -1.5149e+00, -2.3038e+00,  7.2654e-01, -2.1629e-01,\n",
       "         -1.3068e+00, -2.6675e+00, -1.2018e+00, -1.9141e+00, -2.3598e+00,\n",
       "         -2.4764e+00, -6.5267e-02, -2.3301e+00, -2.5212e+00, -3.7299e+00,\n",
       "         -9.0143e-01, -8.4230e-01, -7.0273e-01, -2.2306e+00, -1.6455e+00,\n",
       "          1.7736e+00, -1.2567e+00, -1.2282e+00, -1.3337e+00,  6.6979e-01,\n",
       "         -1.3957e+00, -9.7363e-01, -1.7910e+00, -2.1821e+00, -2.1527e+00,\n",
       "         -7.4131e-01, -2.6003e+00, -1.4188e+00, -2.6265e+00, -6.6437e-01,\n",
       "          7.1799e-01,  9.0848e-01, -1.3217e+00,  4.1825e-01,  9.1868e-01,\n",
       "         -7.3698e-01,  5.0533e-01,  3.5658e-01,  8.8118e-01,  5.8775e-01,\n",
       "         -6.9751e-01, -1.5774e-01, -1.0484e+00, -8.8226e-01,  3.5781e-01,\n",
       "          2.4822e-01, -8.8538e-01, -7.8179e-01,  2.4350e-01, -4.6980e-01,\n",
       "         -2.9234e-01,  9.7416e-01, -1.0690e+00,  1.2866e-01,  9.4167e-01,\n",
       "         -2.7724e-01,  3.3869e-01, -2.7826e-02, -1.2707e+00, -1.6233e+00,\n",
       "         -3.9997e-01, -8.9745e-01, -5.4767e-01,  1.0477e+00, -2.1105e-01,\n",
       "          6.1685e-01,  6.8618e-01, -5.7033e-01, -1.6033e+00, -1.7567e-01,\n",
       "         -6.4501e-01, -9.5442e-01,  3.7536e-01, -3.7767e+00, -9.7619e-01,\n",
       "         -9.6318e-02, -3.9915e+00, -2.9682e+00, -1.9008e-01,  4.8213e+00,\n",
       "          1.7248e+00, -1.7622e-01,  2.0019e+00, -1.4538e+00,  1.4472e+00,\n",
       "          1.1675e+00, -7.5047e-01, -1.5276e+00, -8.5924e-01,  3.6850e+00,\n",
       "         -1.4552e+00, -2.3601e-01,  1.5640e+00,  2.0868e+00,  2.2287e-01,\n",
       "         -2.1335e+00,  1.6971e+00, -2.2437e-01,  3.1570e+00,  2.8032e+00,\n",
       "         -2.0456e-01,  1.3733e+00, -3.2023e-01,  5.4798e-01, -9.6401e-01,\n",
       "         -1.8169e+00,  2.9318e+00,  2.0825e+00, -1.1444e+00,  3.5731e-01,\n",
       "          2.4357e-01,  4.7408e-01,  2.4009e+00, -1.2356e+00, -9.3852e-03,\n",
       "          3.9318e-01, -1.8720e+00,  9.5466e-01,  2.2997e+00,  1.8536e+00,\n",
       "          1.1884e-01,  4.0847e-01,  1.7874e+00, -4.3087e-01, -1.7471e-01,\n",
       "         -1.0268e+00,  6.0553e+00,  1.3256e+00,  3.0533e-01, -1.2261e+00,\n",
       "         -1.6521e+00,  3.5163e+00, -7.0558e-01,  9.6266e-01, -3.3909e+00,\n",
       "         -1.1166e+00,  3.4229e-01,  8.2107e-02, -5.2442e-01,  1.2606e+00,\n",
       "         -8.8879e-01,  2.0369e+00,  1.9192e+00,  1.0571e-01,  1.1338e+00,\n",
       "          3.9542e+00, -1.6059e+00, -3.3453e+00, -1.4702e+00, -1.3970e-01,\n",
       "          1.8975e+00, -7.7629e-01, -2.5060e+00,  3.7166e+00,  6.4690e-01,\n",
       "         -1.2997e+00, -2.6111e+00,  1.9965e+00,  2.6919e+00,  1.2947e-01,\n",
       "          1.6723e+00,  3.1752e+00,  3.4346e+00, -8.6493e-01,  2.5228e-01,\n",
       "          9.9049e-01,  5.0030e-01,  1.9844e+00,  2.2891e+00, -1.8054e+00,\n",
       "          2.2502e+00,  2.2060e+00,  1.3610e+00,  3.9559e+00,  2.4465e+00,\n",
       "          4.1180e-01, -5.1200e-02, -1.1723e+00, -4.3788e-01,  3.2381e+00,\n",
       "         -1.1694e+00,  2.4806e+00,  2.1496e+00,  3.2809e+00,  3.2093e-01,\n",
       "         -4.4041e-01, -6.1217e-01,  3.9108e+00,  1.9536e-01, -2.7850e+00,\n",
       "          1.9026e-01, -1.1767e+00,  2.5267e+00,  8.2703e-01,  2.2755e+00,\n",
       "         -2.9069e-01,  1.9728e+00, -9.8790e-02, -3.2160e-01,  3.3658e+00,\n",
       "          3.5702e-01,  1.2971e+00,  1.6107e+00, -2.0175e-01,  1.3638e+00,\n",
       "         -2.2192e+00,  8.3473e-01,  3.8345e+00,  1.4861e+00, -8.9098e-02,\n",
       "          2.9157e+00,  2.0112e+00, -3.3453e-01,  6.0586e-01,  4.2163e+00,\n",
       "         -1.5159e+00, -1.0410e+00, -1.2729e+00, -1.0820e-02,  1.3176e+00,\n",
       "          1.2791e+00,  1.0630e+00,  1.4218e+00,  1.3142e+00, -1.9187e+00,\n",
       "          2.7610e+00,  8.1900e-01, -2.4574e+00,  1.8749e+00,  2.3193e+00,\n",
       "          2.4295e+00,  2.8564e+00,  5.5950e-01,  3.5047e+00, -1.2570e+00,\n",
       "         -2.4818e+00,  4.0232e+00,  7.7094e-01,  6.1427e-01,  2.1249e+00,\n",
       "         -8.5557e-01, -4.3372e-01, -1.8639e+00,  1.9009e-01,  5.0267e-01,\n",
       "         -8.7088e-01, -3.6680e-01,  2.0895e+00, -6.5143e-01, -2.8811e+00,\n",
       "          1.6321e+00, -8.3290e-01, -1.4761e-01, -1.5156e+00,  1.6843e+00,\n",
       "         -2.4069e+00, -9.1752e-01,  1.9768e+00, -2.4648e-01, -1.3133e+00,\n",
       "         -3.1517e+00, -2.7778e+00, -2.3712e+00,  3.7206e+00,  1.5455e+00,\n",
       "          3.0019e+00, -1.2934e+00,  1.8874e+00,  3.3099e+00,  1.9975e+00,\n",
       "          3.7004e+00, -9.9748e-02,  1.7290e+00,  1.8038e+00,  1.8816e-01,\n",
       "         -2.1764e+00,  3.2666e+00,  5.2780e-01,  2.3172e+00,  6.4464e-01,\n",
       "          1.9931e+00,  1.7404e+00,  1.3216e+00, -2.0827e+00,  3.3921e+00,\n",
       "          8.6611e-01,  2.6243e+00, -1.5582e+00,  2.4653e-01, -2.5859e+00,\n",
       "          3.4298e+00, -4.5036e-01, -1.7418e+00,  2.3527e+00, -2.6286e-01,\n",
       "          3.8946e+00,  2.1729e+00,  1.2163e+00, -3.1901e-01,  3.5901e+00,\n",
       "          2.4755e+00, -2.1637e+00,  3.9738e-01,  4.2835e+00, -7.7842e-01,\n",
       "         -1.6249e+00,  1.7570e+00, -1.4345e+00, -1.3538e+00,  2.0826e+00,\n",
       "          2.2554e+00,  3.2404e+00,  4.1027e+00,  2.1528e+00, -1.1894e+00,\n",
       "          2.9370e+00,  3.7155e+00, -7.4024e-01, -7.3692e-01,  1.3338e+00,\n",
       "         -1.4210e+00,  2.4192e+00, -7.9621e-01, -1.0211e-01,  1.9835e+00,\n",
       "         -5.3217e-01,  8.1104e-01,  1.4394e+00,  2.3506e+00,  6.4770e-01,\n",
       "          1.5342e+00,  2.7757e+00, -8.8900e-01,  3.2820e+00, -1.2328e+00,\n",
       "         -2.4746e-01, -1.1079e+00,  1.6757e-01, -2.0629e+00, -8.9273e-01,\n",
       "          1.2892e-01, -2.1958e+00,  4.0777e+00,  1.2204e+00,  2.5916e+00,\n",
       "         -1.2562e+00,  9.1342e-01,  4.5374e-01, -1.0475e-01, -1.1297e+00,\n",
       "         -1.1128e+00, -1.1780e+00,  1.0672e+00,  1.9804e+00,  3.2046e+00,\n",
       "          1.6273e+00,  2.5926e+00,  2.4801e+00,  2.5658e+00, -3.6528e-01,\n",
       "          3.6378e+00,  2.0538e+00,  2.1246e+00,  3.4421e+00,  2.4459e+00,\n",
       "         -1.9829e+00,  3.6991e+00, -1.0260e+00,  8.5437e-01,  2.9470e+00,\n",
       "         -2.0819e+00,  1.2462e+00,  2.0010e+00, -1.9022e-01, -1.4098e+00,\n",
       "          9.9465e-01,  9.2339e-01, -1.1073e+00, -1.5149e+00,  2.6531e+00,\n",
       "          1.7761e+00, -1.5062e-01,  1.2213e+00, -2.1061e+00, -1.2555e+00,\n",
       "         -1.8611e-01, -5.0846e-01,  1.3772e+00,  5.4724e+00, -2.3131e-01,\n",
       "          1.1448e+00,  6.2604e-01,  1.3200e+00,  1.7259e+00,  2.5599e+00,\n",
       "          1.3586e+00, -1.1226e+00, -2.0982e+00,  2.5318e-01,  1.7148e-01,\n",
       "          1.9717e+00, -5.0811e-01,  1.6151e+00,  8.7852e-01,  5.0454e-01,\n",
       "          2.4716e-01,  2.1555e+00,  1.4269e+00,  2.2549e+00,  2.6312e+00,\n",
       "         -2.9677e+00,  3.8779e+00,  6.1730e-01,  2.2594e+00, -2.0599e+00,\n",
       "         -1.1128e-01,  1.3141e+00,  1.0123e-01, -2.5470e-02,  1.7056e+00,\n",
       "          2.9614e+00,  1.8209e+00,  1.1510e+00,  2.5236e+00,  1.7502e+00,\n",
       "          1.8782e+00,  6.5571e-01,  3.6227e+00,  9.9799e-01,  2.1915e+00,\n",
       "          5.6232e-01, -2.1992e+00, -7.7527e-01,  4.0075e+00,  2.3180e+00,\n",
       "         -1.0813e+00,  6.3279e-01, -2.0277e+00,  2.2615e+00,  2.3834e+00,\n",
       "          1.2505e+00,  1.8983e+00, -2.0992e+00,  3.0672e+00, -4.9827e-01,\n",
       "          4.5526e-01,  1.2787e+00,  8.6877e-01, -1.4807e+00,  2.6884e+00,\n",
       "          2.9724e-01,  4.4825e+00,  2.5642e+00, -4.5902e-01,  1.6458e-01,\n",
       "          1.6043e-01,  1.1506e+00,  1.6312e+00,  4.8932e-01, -1.8283e+00,\n",
       "          1.0709e-01,  9.1737e-01,  5.0530e+00,  2.6883e+00,  2.3359e+00,\n",
       "          2.3395e-01, -1.1019e+00,  5.4518e-01, -2.3457e+00,  3.4975e+00,\n",
       "          1.0197e+00, -7.8878e-01,  8.8946e-02,  2.6127e-02,  1.3898e+00,\n",
       "          1.1784e+00,  1.5036e+00,  1.0212e+00,  2.9836e+00,  1.1327e+00,\n",
       "         -3.1707e-01, -1.1368e+00, -1.5737e+00, -1.0071e+00,  3.5148e+00,\n",
       "         -1.8235e-01, -2.9642e-01,  1.7791e-01, -1.3322e-03, -2.2185e+00,\n",
       "          2.9976e+00,  3.9582e+00,  2.3004e+00,  3.4739e+00, -5.7802e-02,\n",
       "         -1.1712e+00, -2.1071e+00, -1.7375e-01,  3.8002e+00, -5.7358e-01,\n",
       "         -2.4879e+00,  1.1390e+00,  5.3478e-01,  1.7880e+00,  7.9789e-01,\n",
       "         -1.3303e+00,  2.4968e+00,  1.5273e+00,  2.7249e-05, -2.9356e+00,\n",
       "          9.4939e-01,  3.4264e+00, -1.4032e+00,  1.1011e-02,  1.6145e+00,\n",
       "         -7.9024e-01,  1.2141e+00, -5.7566e-01,  1.9927e+00, -9.2020e-01,\n",
       "          4.6132e-01,  1.9450e+00,  6.2578e-01, -2.3694e+00,  3.9430e+00,\n",
       "          1.4689e+00,  4.4841e+00, -1.3428e+00,  1.4165e+00, -1.0022e+00,\n",
       "         -1.1895e+00,  3.1577e+00,  1.6272e+00, -1.1157e-01,  2.6244e+00,\n",
       "          1.0557e+00,  2.6676e-01,  1.4295e+00,  2.2738e-01,  1.3002e+00,\n",
       "          1.4158e+00,  5.9812e-01,  1.3006e+00, -2.8094e-01, -2.3191e+00,\n",
       "         -1.6815e+00, -1.5132e+00,  2.9192e-01, -3.6691e-01,  3.6233e+00,\n",
       "         -1.7011e+00,  3.7332e-01,  2.8571e+00, -2.6531e-02, -2.8400e+00,\n",
       "         -1.1897e-01, -1.6112e-01,  1.1138e+00,  1.4715e+00, -6.8743e-01,\n",
       "          7.3102e-01,  2.6858e+00,  9.5404e-01,  1.5153e+00,  1.0991e-01,\n",
       "          3.2075e+00, -5.0874e-01, -7.1975e-02, -6.0168e-01, -2.8005e-01,\n",
       "         -1.2578e+00,  1.4029e+00,  4.3405e+00,  2.8029e+00,  3.0411e+00,\n",
       "         -3.6506e-01,  1.4111e+00,  1.2612e+00,  8.0560e-01,  1.8300e+00,\n",
       "          6.4343e-01,  3.8968e+00,  3.0437e+00,  5.1548e-01,  8.6385e-01,\n",
       "          3.2068e+00,  4.5868e+00,  5.5380e-01, -3.2656e-01, -1.0966e+00,\n",
       "         -3.4691e-01,  1.1120e+00,  4.1411e-01, -1.2026e+00,  6.3070e-01,\n",
       "         -1.4376e+00,  1.5459e+00, -4.5574e-01, -1.1455e+00,  1.3693e+00,\n",
       "          1.0086e+00,  3.1235e+00, -1.2624e+00, -1.1528e+00, -1.9561e+00,\n",
       "          1.9389e-01, -7.9911e-01, -4.1393e-01, -2.7507e+00, -4.4664e-01,\n",
       "          7.4728e-01, -1.0629e+00, -1.2291e+00, -3.5280e+00, -1.7963e+00,\n",
       "         -1.3815e+00, -1.5029e+00, -1.2842e+00, -6.2347e-01, -8.7474e-01,\n",
       "          1.4565e+00, -2.4195e+00, -4.9956e-01, -1.7927e+00, -1.6093e+00,\n",
       "         -5.3746e-01, -5.2592e-02, -2.3164e+00, -4.2446e-02,  4.0591e-01,\n",
       "         -7.1437e-01,  6.3670e-01, -7.7664e-01, -1.1919e+00, -1.9108e-01,\n",
       "         -1.5661e+00, -6.1661e-01, -2.0061e+00, -1.6843e+00, -1.3276e+00,\n",
       "          4.8846e-02, -1.4062e+00, -6.7832e-01, -2.1930e+00, -9.8955e-01,\n",
       "         -2.1655e+00,  9.4925e-02, -1.2354e+00, -3.9378e-01,  2.4294e+00,\n",
       "         -8.6256e-01, -5.4158e-01, -1.5885e+00, -3.1520e+00,  4.6506e-01,\n",
       "         -7.6953e-01,  2.4919e-01,  7.2441e-01,  7.3197e-01, -1.3463e+00,\n",
       "         -7.4020e-01, -3.1777e-01, -1.3027e+00, -1.4480e+00, -9.6853e-01,\n",
       "         -6.2927e-01, -1.6739e+00, -1.6304e-01, -2.0381e+00, -1.9746e+00,\n",
       "         -1.5032e+00, -3.6657e+00, -2.9092e+00, -2.1578e+00, -1.5359e+00,\n",
       "         -1.1753e+00, -4.6530e-01, -2.1000e+00, -5.0948e-01,  7.2312e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7581e-01, -2.4327e-01, -2.2948e+00, -1.9053e+00, -2.4730e+00,\n",
       "         -2.1047e-01, -3.5750e+00, -1.7740e+00, -1.9271e+00, -9.9620e-01,\n",
       "          1.6648e+00, -4.0727e-01, -1.0489e+00, -1.4315e+00, -1.5815e+00,\n",
       "         -7.8157e-01, -7.4532e-01, -1.7407e+00, -2.1929e+00, -1.5676e+00,\n",
       "         -1.9657e+00,  6.2797e-01, -9.6306e-01, -6.2646e-01, -1.6638e+00,\n",
       "         -2.4488e+00, -1.5220e+00, -1.8061e+00, -2.9531e-01, -9.5689e-01,\n",
       "         -4.1994e+00, -1.6529e+00, -2.1386e+00, -1.8823e+00, -1.0101e+00,\n",
       "         -3.7073e+00, -1.9570e+00, -3.5193e+00,  5.8777e-01, -1.9691e+00,\n",
       "         -7.9854e-01, -1.2132e+00, -3.8929e-01,  1.2133e+00, -9.5485e-01,\n",
       "         -4.0284e-01, -1.1763e+00, -8.9208e-01, -1.9620e+00, -3.0837e+00,\n",
       "         -2.4837e+00,  8.9620e-01, -7.8899e-01, -1.2444e+00, -1.4835e+00,\n",
       "         -2.8464e+00, -2.3781e+00, -3.0220e+00, -3.1995e+00,  1.3249e+00,\n",
       "         -7.2586e-01, -2.5133e+00,  1.6638e-01,  3.1705e-01, -7.1929e-02,\n",
       "         -5.3640e-01,  1.0295e-01, -2.5600e+00,  7.7942e-01, -7.7585e-01,\n",
       "         -1.1670e+00, -1.2409e+00, -1.2985e+00,  2.7721e+00, -2.1506e+00,\n",
       "         -3.0375e-01, -2.1032e+00, -1.9884e+00,  1.6839e+00, -2.7577e-01,\n",
       "          1.3132e+00, -1.0702e+00, -1.3695e+00, -2.1457e-01, -2.2169e+00,\n",
       "         -1.3522e+00, -5.6097e-01, -8.7562e-02, -1.4033e+00, -6.5542e-01,\n",
       "         -2.0794e+00, -8.7467e-01, -5.9160e-01, -2.1492e+00, -2.3209e+00,\n",
       "          1.6891e-01, -2.0613e+00, -3.3705e+00,  1.1662e+00, -8.3245e-01,\n",
       "         -1.3602e+00,  8.7632e-01, -1.6762e+00,  1.3720e+00, -1.4083e+00,\n",
       "         -1.6881e+00, -2.1070e+00, -1.2710e+00, -2.8458e+00, -1.5477e+00,\n",
       "         -2.6597e+00,  3.5804e+00, -1.0119e+00, -1.5849e+00, -1.9400e+00,\n",
       "         -3.7408e+00, -1.7316e+00,  1.5046e+00, -2.0152e+00, -2.9823e+00,\n",
       "         -2.3851e+00, -2.0872e+00, -1.4744e+00, -3.1577e+00, -2.9992e+00,\n",
       "         -1.6322e+00,  9.4645e-01, -9.8129e-01,  1.3321e+00, -1.6527e+00,\n",
       "         -2.2768e+00, -2.1306e+00, -1.8192e+00, -1.7746e+00, -1.8930e+00,\n",
       "         -1.1564e-01, -2.9867e+00, -2.0714e+00, -1.1884e+00, -2.7790e+00,\n",
       "         -2.6863e+00, -7.8634e-01, -1.0347e+00, -1.2368e+00, -1.9683e+00,\n",
       "         -5.5666e-02, -2.5832e-01,  3.6031e-01, -1.3363e+00,  6.0761e-01,\n",
       "         -4.8343e-01,  1.4115e-01,  1.6733e+00, -9.9791e-02, -6.8208e-02,\n",
       "         -5.3669e-01, -4.0609e-02, -7.7106e-01,  1.3612e+00,  1.7870e-01,\n",
       "         -1.3043e-02, -1.0130e+00, -1.4132e+00,  5.1022e-02,  4.5194e-01,\n",
       "          9.6733e-01,  1.2565e+00,  1.0161e+00,  1.5242e+00, -8.5839e-01,\n",
       "         -9.4580e-01, -3.3924e-01, -5.6126e-01, -5.7542e-01,  2.4383e-02,\n",
       "         -1.0248e-01, -1.0171e+00, -8.1178e-01, -4.1765e-01, -1.1828e+00,\n",
       "         -1.0323e+00,  7.8326e-01, -1.2737e+00,  6.9864e-01, -5.2549e-01,\n",
       "          6.7328e-01, -5.9514e-01,  3.1796e-01,  2.7238e-01,  1.9678e-01,\n",
       "          1.6584e+00, -1.0116e+00, -1.1024e+00, -9.9737e-01,  7.8572e-01,\n",
       "         -3.0175e-02, -1.5036e+00, -1.5265e+00, -9.5965e-01, -7.3548e-01,\n",
       "         -4.4472e-02, -1.8099e+00, -2.3086e-01, -2.8251e-01, -7.9630e-01,\n",
       "         -1.6597e+00,  5.1289e-01,  1.5436e-01, -2.5325e-01, -5.5411e-01,\n",
       "          6.4743e-01, -1.6378e+00, -9.5787e-01, -1.5387e+00, -1.1605e+00,\n",
       "         -2.3075e-01, -1.0414e-01, -1.0750e+00, -1.2473e+00, -1.5180e+00,\n",
       "          5.6684e-01,  8.7548e-01, -3.9811e-01, -4.8407e-01, -4.3806e-01,\n",
       "         -7.7540e-01, -9.4063e-01, -2.7500e-01,  9.6019e-01, -2.9739e-01,\n",
       "         -1.3886e+00, -1.6496e+00, -5.6478e-01, -9.4133e-01, -1.2558e+00,\n",
       "         -4.1203e-01,  5.7338e-01, -6.9118e-01, -1.1736e+00, -1.7971e+00,\n",
       "         -1.3849e+00,  6.9894e-01, -1.6228e+00, -3.5311e-01, -1.1085e+00,\n",
       "         -4.0942e-01, -8.0359e-02, -8.6635e-01,  4.4706e-01, -7.8113e-02,\n",
       "          3.5134e-02, -8.4342e-01,  1.0982e+00, -4.1953e-01, -4.9197e-01,\n",
       "         -1.5255e+00, -5.5978e-01, -7.4430e-01,  4.8341e-01, -7.4327e-01,\n",
       "         -8.4659e-01,  1.2850e-02,  1.1232e+00, -7.5626e-01, -1.0639e+00,\n",
       "         -1.6374e-01,  1.1506e-01, -6.5056e-01,  9.6925e-01, -3.6962e-01,\n",
       "         -1.1552e-01, -8.0188e-01, -1.2658e-01,  3.8200e-01,  2.0108e-01,\n",
       "         -4.5344e-01,  2.2526e-01,  1.3947e-01,  4.3588e-01,  5.3917e-01,\n",
       "          2.8710e-02,  7.2650e-01,  3.7917e-01,  2.5332e+00,  9.0858e-01,\n",
       "          1.8092e+00, -8.8829e-01, -5.7052e-01,  1.7513e-01, -1.4640e+00,\n",
       "         -1.3814e+00,  1.9585e-01,  2.7141e-01,  3.7419e-01,  7.6839e-02,\n",
       "         -1.0274e+00,  2.7901e-01, -2.3123e-01, -4.6017e-01, -5.4064e-02,\n",
       "         -1.5334e+00, -9.2549e-01, -2.0649e-01, -6.1379e-01, -2.1027e+00,\n",
       "         -3.1208e+00, -1.0726e+00, -8.4162e-01, -1.7463e+00, -3.0136e+00,\n",
       "          1.4538e+00, -1.9595e+00, -1.4885e+00, -1.8362e+00, -3.6970e-01,\n",
       "         -1.2272e+00, -1.5149e+00, -2.3038e+00,  7.2654e-01, -2.1629e-01,\n",
       "         -1.3068e+00, -2.6675e+00, -1.2018e+00, -1.9141e+00, -2.3598e+00,\n",
       "         -2.4764e+00, -6.5267e-02, -2.3301e+00, -2.5212e+00, -3.7299e+00,\n",
       "         -9.0143e-01, -8.4230e-01, -7.0273e-01, -2.2306e+00, -1.6455e+00,\n",
       "          1.7736e+00, -1.2567e+00, -1.2282e+00, -1.3337e+00,  6.6979e-01,\n",
       "         -1.3957e+00, -9.7363e-01, -1.7910e+00, -2.1821e+00, -2.1527e+00,\n",
       "         -7.4131e-01, -2.6003e+00, -1.4188e+00, -2.6265e+00, -6.6437e-01,\n",
       "          7.1799e-01,  9.0848e-01, -1.3217e+00,  4.1825e-01,  9.1868e-01,\n",
       "         -7.3698e-01,  5.0533e-01,  3.5658e-01,  8.8118e-01,  5.8775e-01,\n",
       "         -6.9751e-01, -1.5774e-01, -1.0484e+00, -8.8226e-01,  3.5781e-01,\n",
       "          2.4822e-01, -8.8538e-01, -7.8179e-01,  2.4350e-01, -4.6980e-01,\n",
       "         -2.9234e-01,  9.7416e-01, -1.0690e+00,  1.2866e-01,  9.4167e-01,\n",
       "         -2.7724e-01,  3.3869e-01, -2.7826e-02, -1.2707e+00, -1.6233e+00,\n",
       "         -3.9997e-01, -8.9745e-01, -5.4767e-01,  1.0477e+00, -2.1105e-01,\n",
       "          6.1685e-01,  6.8618e-01, -5.7033e-01, -1.6033e+00, -1.7567e-01,\n",
       "         -6.4501e-01, -9.5442e-01,  3.7536e-01, -3.7767e+00, -9.7619e-01,\n",
       "         -9.6318e-02, -3.9915e+00, -2.9682e+00, -1.9008e-01,  4.8213e+00,\n",
       "          1.7248e+00, -1.7622e-01,  2.0019e+00, -1.4538e+00,  1.4472e+00,\n",
       "          1.1675e+00, -7.5047e-01, -1.5276e+00, -8.5924e-01,  3.6850e+00,\n",
       "         -1.4552e+00, -2.3601e-01,  1.5640e+00,  2.0868e+00,  2.2287e-01,\n",
       "         -2.1335e+00,  1.6971e+00, -2.2437e-01,  3.1570e+00,  2.8032e+00,\n",
       "         -2.0456e-01,  1.3733e+00, -3.2023e-01,  5.4798e-01, -9.6401e-01,\n",
       "         -1.8169e+00,  2.9318e+00,  2.0825e+00, -1.1444e+00,  3.5731e-01,\n",
       "          2.4357e-01,  4.7408e-01,  2.4009e+00, -1.2356e+00, -9.3852e-03,\n",
       "          3.9318e-01, -1.8720e+00,  9.5466e-01,  2.2997e+00,  1.8536e+00,\n",
       "          1.1884e-01,  4.0847e-01,  1.7874e+00, -4.3087e-01, -1.7471e-01,\n",
       "         -1.0268e+00,  6.0553e+00,  1.3256e+00,  3.0533e-01, -1.2261e+00,\n",
       "         -1.6521e+00,  3.5163e+00, -7.0558e-01,  9.6266e-01, -3.3909e+00,\n",
       "         -1.1166e+00,  3.4229e-01,  8.2107e-02, -5.2442e-01,  1.2606e+00,\n",
       "         -8.8879e-01,  2.0369e+00,  1.9192e+00,  1.0571e-01,  1.1338e+00,\n",
       "          3.9542e+00, -1.6059e+00, -3.3453e+00, -1.4702e+00, -1.3970e-01,\n",
       "          1.8975e+00, -7.7629e-01, -2.5060e+00,  3.7166e+00,  6.4690e-01,\n",
       "         -1.2997e+00, -2.6111e+00,  1.9965e+00,  2.6919e+00,  1.2947e-01,\n",
       "          1.6723e+00,  3.1752e+00,  3.4346e+00, -8.6493e-01,  2.5228e-01,\n",
       "          9.9049e-01,  5.0030e-01,  1.9844e+00,  2.2891e+00, -1.8054e+00,\n",
       "          2.2502e+00,  2.2060e+00,  1.3610e+00,  3.9559e+00,  2.4465e+00,\n",
       "          4.1180e-01, -5.1200e-02, -1.1723e+00, -4.3788e-01,  3.2381e+00,\n",
       "         -1.1694e+00,  2.4806e+00,  2.1496e+00,  3.2809e+00,  3.2093e-01,\n",
       "         -4.4041e-01, -6.1217e-01,  3.9108e+00,  1.9536e-01, -2.7850e+00,\n",
       "          1.9026e-01, -1.1767e+00,  2.5267e+00,  8.2703e-01,  2.2755e+00,\n",
       "         -2.9069e-01,  1.9728e+00, -9.8790e-02, -3.2160e-01,  3.3658e+00,\n",
       "          3.5702e-01,  1.2971e+00,  1.6107e+00, -2.0175e-01,  1.3638e+00,\n",
       "         -2.2192e+00,  8.3473e-01,  3.8345e+00,  1.4861e+00, -8.9098e-02,\n",
       "          2.9157e+00,  2.0112e+00, -3.3453e-01,  6.0586e-01,  4.2163e+00,\n",
       "         -1.5159e+00, -1.0410e+00, -1.2729e+00, -1.0820e-02,  1.3176e+00,\n",
       "          1.2791e+00,  1.0630e+00,  1.4218e+00,  1.3142e+00, -1.9187e+00,\n",
       "          2.7610e+00,  8.1900e-01, -2.4574e+00,  1.8749e+00,  2.3193e+00,\n",
       "          2.4295e+00,  2.8564e+00,  5.5950e-01,  3.5047e+00, -1.2570e+00,\n",
       "         -2.4818e+00,  4.0232e+00,  7.7094e-01,  6.1427e-01,  2.1249e+00,\n",
       "         -8.5557e-01, -4.3372e-01, -1.8639e+00,  1.9009e-01,  5.0267e-01,\n",
       "         -8.7088e-01, -3.6680e-01,  2.0895e+00, -6.5143e-01, -2.8811e+00,\n",
       "          1.6321e+00, -8.3290e-01, -1.4761e-01, -1.5156e+00,  1.6843e+00,\n",
       "         -2.4069e+00, -9.1752e-01,  1.9768e+00, -2.4648e-01, -1.3133e+00,\n",
       "         -3.1517e+00, -2.7778e+00, -2.3712e+00,  3.7206e+00,  1.5455e+00,\n",
       "          3.0019e+00, -1.2934e+00,  1.8874e+00,  3.3099e+00,  1.9975e+00,\n",
       "          3.7004e+00, -9.9748e-02,  1.7290e+00,  1.8038e+00,  1.8816e-01,\n",
       "         -2.1764e+00,  3.2666e+00,  5.2780e-01,  2.3172e+00,  6.4464e-01,\n",
       "          1.9931e+00,  1.7404e+00,  1.3216e+00, -2.0827e+00,  3.3921e+00,\n",
       "          8.6611e-01,  2.6243e+00, -1.5582e+00,  2.4653e-01, -2.5859e+00,\n",
       "          3.4298e+00, -4.5036e-01, -1.7418e+00,  2.3527e+00, -2.6286e-01,\n",
       "          3.8946e+00,  2.1729e+00,  1.2163e+00, -3.1901e-01,  3.5901e+00,\n",
       "          2.4755e+00, -2.1637e+00,  3.9738e-01,  4.2835e+00, -7.7842e-01,\n",
       "         -1.6249e+00,  1.7570e+00, -1.4345e+00, -1.3538e+00,  2.0826e+00,\n",
       "          2.2554e+00,  3.2404e+00,  4.1027e+00,  2.1528e+00, -1.1894e+00,\n",
       "          2.9370e+00,  3.7155e+00, -7.4024e-01, -7.3692e-01,  1.3338e+00,\n",
       "         -1.4210e+00,  2.4192e+00, -7.9621e-01, -1.0211e-01,  1.9835e+00,\n",
       "         -5.3217e-01,  8.1104e-01,  1.4394e+00,  2.3506e+00,  6.4770e-01,\n",
       "          1.5342e+00,  2.7757e+00, -8.8900e-01,  3.2820e+00, -1.2328e+00,\n",
       "         -2.4746e-01, -1.1079e+00,  1.6757e-01, -2.0629e+00, -8.9273e-01,\n",
       "          1.2892e-01, -2.1958e+00,  4.0777e+00,  1.2204e+00,  2.5916e+00,\n",
       "         -1.2562e+00,  9.1342e-01,  4.5374e-01, -1.0475e-01, -1.1297e+00,\n",
       "         -1.1128e+00, -1.1780e+00,  1.0672e+00,  1.9804e+00,  3.2046e+00,\n",
       "          1.6273e+00,  2.5926e+00,  2.4801e+00,  2.5658e+00, -3.6528e-01,\n",
       "          3.6378e+00,  2.0538e+00,  2.1246e+00,  3.4421e+00,  2.4459e+00,\n",
       "         -1.9829e+00,  3.6991e+00, -1.0260e+00,  8.5437e-01,  2.9470e+00,\n",
       "         -2.0819e+00,  1.2462e+00,  2.0010e+00, -1.9022e-01, -1.4098e+00,\n",
       "          9.9465e-01,  9.2339e-01, -1.1073e+00, -1.5149e+00,  2.6531e+00,\n",
       "          1.7761e+00, -1.5062e-01,  1.2213e+00, -2.1061e+00, -1.2555e+00,\n",
       "         -1.8611e-01, -5.0846e-01,  1.3772e+00,  5.4724e+00, -2.3131e-01,\n",
       "          1.1448e+00,  6.2604e-01,  1.3200e+00,  1.7259e+00,  2.5599e+00,\n",
       "          1.3586e+00, -1.1226e+00, -2.0982e+00,  2.5318e-01,  1.7148e-01,\n",
       "          1.9717e+00, -5.0811e-01,  1.6151e+00,  8.7852e-01,  5.0454e-01,\n",
       "          2.4716e-01,  2.1555e+00,  1.4269e+00,  2.2549e+00,  2.6312e+00,\n",
       "         -2.9677e+00,  3.8779e+00,  6.1730e-01,  2.2594e+00, -2.0599e+00,\n",
       "         -1.1128e-01,  1.3141e+00,  1.0123e-01, -2.5470e-02,  1.7056e+00,\n",
       "          2.9614e+00,  1.8209e+00,  1.1510e+00,  2.5236e+00,  1.7502e+00,\n",
       "          1.8782e+00,  6.5571e-01,  3.6227e+00,  9.9799e-01,  2.1915e+00,\n",
       "          5.6232e-01, -2.1992e+00, -7.7527e-01,  4.0075e+00,  2.3180e+00,\n",
       "         -1.0813e+00,  6.3279e-01, -2.0277e+00,  2.2615e+00,  2.3834e+00,\n",
       "          1.2505e+00,  1.8983e+00, -2.0992e+00,  3.0672e+00, -4.9827e-01,\n",
       "          4.5526e-01,  1.2787e+00,  8.6877e-01, -1.4807e+00,  2.6884e+00,\n",
       "          2.9724e-01,  4.4825e+00,  2.5642e+00, -4.5902e-01,  1.6458e-01,\n",
       "          1.6043e-01,  1.1506e+00,  1.6312e+00,  4.8932e-01, -1.8283e+00,\n",
       "          1.0709e-01,  9.1737e-01,  5.0530e+00,  2.6883e+00,  2.3359e+00,\n",
       "          2.3395e-01, -1.1019e+00,  5.4518e-01, -2.3457e+00,  3.4975e+00,\n",
       "          1.0197e+00, -7.8878e-01,  8.8946e-02,  2.6127e-02,  1.3898e+00,\n",
       "          1.1784e+00,  1.5036e+00,  1.0212e+00,  2.9836e+00,  1.1327e+00,\n",
       "         -3.1707e-01, -1.1368e+00, -1.5737e+00, -1.0071e+00,  3.5148e+00,\n",
       "         -1.8235e-01, -2.9642e-01,  1.7791e-01, -1.3322e-03, -2.2185e+00,\n",
       "          2.9976e+00,  3.9582e+00,  2.3004e+00,  3.4739e+00, -5.7802e-02,\n",
       "         -1.1712e+00, -2.1071e+00, -1.7375e-01,  3.8002e+00, -5.7358e-01,\n",
       "         -2.4879e+00,  1.1390e+00,  5.3478e-01,  1.7880e+00,  7.9789e-01,\n",
       "         -1.3303e+00,  2.4968e+00,  1.5273e+00,  2.7249e-05, -2.9356e+00,\n",
       "          9.4939e-01,  3.4264e+00, -1.4032e+00,  1.1011e-02,  1.6145e+00,\n",
       "         -7.9024e-01,  1.2141e+00, -5.7566e-01,  1.9927e+00, -9.2020e-01,\n",
       "          4.6132e-01,  1.9450e+00,  6.2578e-01, -2.3694e+00,  3.9430e+00,\n",
       "          1.4689e+00,  4.4841e+00, -1.3428e+00,  1.4165e+00, -1.0022e+00,\n",
       "         -1.1895e+00,  3.1577e+00,  1.6272e+00, -1.1157e-01,  2.6244e+00,\n",
       "          1.0557e+00,  2.6676e-01,  1.4295e+00,  2.2738e-01,  1.3002e+00,\n",
       "          1.4158e+00,  5.9812e-01,  1.3006e+00, -2.8094e-01, -2.3191e+00,\n",
       "         -1.6815e+00, -1.5132e+00,  2.9192e-01, -3.6691e-01,  3.6233e+00,\n",
       "         -1.7011e+00,  3.7332e-01,  2.8571e+00, -2.6531e-02, -2.8400e+00,\n",
       "         -1.1897e-01, -1.6112e-01,  1.1138e+00,  1.4715e+00, -6.8743e-01,\n",
       "          7.3102e-01,  2.6858e+00,  9.5404e-01,  1.5153e+00,  1.0991e-01,\n",
       "          3.2075e+00, -5.0874e-01, -7.1975e-02, -6.0168e-01, -2.8005e-01,\n",
       "         -1.2578e+00,  1.4029e+00,  4.3405e+00,  2.8029e+00,  3.0411e+00,\n",
       "         -3.6506e-01,  1.4111e+00,  1.2612e+00,  8.0560e-01,  1.8300e+00,\n",
       "          6.4343e-01,  3.8968e+00,  3.0437e+00,  5.1548e-01,  8.6385e-01,\n",
       "          3.2068e+00,  4.5868e+00,  5.5380e-01, -3.2656e-01, -1.0966e+00,\n",
       "         -3.4691e-01,  1.1120e+00,  4.1411e-01, -1.2026e+00,  6.3070e-01,\n",
       "         -1.4376e+00,  1.5459e+00, -4.5574e-01, -1.1455e+00,  1.3693e+00,\n",
       "          1.0086e+00,  3.1235e+00, -1.2624e+00, -1.1528e+00, -1.9561e+00,\n",
       "          1.9389e-01, -7.9911e-01, -4.1393e-01, -2.7507e+00, -4.4664e-01,\n",
       "          7.4728e-01, -1.0629e+00, -1.2291e+00, -3.5280e+00, -1.7963e+00,\n",
       "         -1.3815e+00, -1.5029e+00, -1.2842e+00, -6.2347e-01, -8.7474e-01,\n",
       "          1.4565e+00, -2.4195e+00, -4.9956e-01, -1.7927e+00, -1.6093e+00,\n",
       "         -5.3746e-01, -5.2592e-02, -2.3164e+00, -4.2446e-02,  4.0591e-01,\n",
       "         -7.1437e-01,  6.3670e-01, -7.7664e-01, -1.1919e+00, -1.9108e-01,\n",
       "         -1.5661e+00, -6.1661e-01, -2.0061e+00, -1.6843e+00, -1.3276e+00,\n",
       "          4.8846e-02, -1.4062e+00, -6.7832e-01, -2.1930e+00, -9.8955e-01,\n",
       "         -2.1655e+00,  9.4925e-02, -1.2354e+00, -3.9378e-01,  2.4294e+00,\n",
       "         -8.6256e-01, -5.4158e-01, -1.5885e+00, -3.1520e+00,  4.6506e-01,\n",
       "         -7.6953e-01,  2.4919e-01,  7.2441e-01,  7.3197e-01, -1.3463e+00,\n",
       "         -7.4020e-01, -3.1777e-01, -1.3027e+00, -1.4480e+00, -9.6853e-01,\n",
       "         -6.2927e-01, -1.6739e+00, -1.6304e-01, -2.0381e+00, -1.9746e+00,\n",
       "         -1.5032e+00, -3.6657e+00, -2.9092e+00, -2.1578e+00, -1.5359e+00,\n",
       "         -1.1753e+00, -4.6530e-01, -2.1000e+00, -5.0948e-01,  7.2312e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
